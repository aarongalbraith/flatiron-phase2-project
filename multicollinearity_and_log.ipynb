{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "\n",
    "# make subsets of the columns\n",
    "num_cont = ['price', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_garage', 'sqft_patio']\n",
    "num_disc = ['price', 'bedrooms', 'bathrooms', 'floors', 'yr_built', 'yr_renovated']\n",
    "cat = ['price', 'waterfront', 'greenbelt', 'nuisance', 'view', 'condition', 'grade', 'heat_source']\n",
    "ignore = ['id', 'date', 'lat', 'long', 'address']\n",
    "\n",
    "# create sub-dfs and standardize numeric values\n",
    "df_cont_std = df[num_cont].copy()\n",
    "for col in df_cont_std:\n",
    "    df_cont_std[col] = (df_cont_std[col] - df_cont_std[col].mean()) / df_cont_std[col].std()\n",
    "\n",
    "df_disc_std = df[num_disc].copy()\n",
    "for col in df_disc_std:\n",
    "    df_disc_std[col] = (df_disc_std[col] - df_disc_std[col].mean()) / df_disc_std[col].std()\n",
    "\n",
    "df_cat = df[cat].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check multicollinearity before modifying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save absolute value of correlation matrix as a data frame\n",
    "# converts all values to absolute value\n",
    "# stacks the row:column pairs into a multindex\n",
    "# reset the index to set the multindex to seperate columns\n",
    "# sort values. 0 is the column automatically generated by the stacking\n",
    "\n",
    "df_mc=df.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "df_mc['pairs'] = list(zip(df_mc.level_0, df_mc.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "df_mc.set_index(['pairs'], inplace = True)\n",
    "\n",
    "# drop level columns\n",
    "df_mc.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "df_mc.columns = ['cc']\n",
    "\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themse\n",
    "# for the sake of exercise, kept it in.\n",
    "df_mc.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc[(df_mc.cc > .55) & (df_mc.cc < 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the dataframe based on info from cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect a list of outlier data past a certain threshold of standard deviations\n",
    "\n",
    "threshold = 7.5\n",
    "outliers = set()\n",
    "for col in df_cont_std:\n",
    "    outliers = outliers.union(set(df_cont_std[df_cont_std[col] > threshold].index))\n",
    "    \n",
    "len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['garage'] = df['sqft_garage'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['renovated'] = df['yr_renovated'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[ignore], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['waterfront', 'greenbelt', 'nuisance', 'view', 'condition', 'grade', 'heat_source'])\n",
    "df = df.drop(['waterfront_NO', 'greenbelt_NO', 'nuisance_NO', 'view_NONE', 'condition_Average', 'grade_7 Average',\n",
    "        'heat_source_Other'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save absolute value of correlation matrix as a data frame\n",
    "# converts all values to absolute value\n",
    "# stacks the row:column pairs into a multindex\n",
    "# reset the index to set the multindex to seperate columns\n",
    "# sort values. 0 is the column automatically generated by the stacking\n",
    "\n",
    "df_mc=df.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "# zip the variable name columns (Which were only named level_0 and level_1 by default) in a new column named \"pairs\"\n",
    "df_mc['pairs'] = list(zip(df_mc.level_0, df_mc.level_1))\n",
    "\n",
    "# set index to pairs\n",
    "df_mc.set_index(['pairs'], inplace = True)\n",
    "\n",
    "# drop level columns\n",
    "df_mc.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# rename correlation column as cc rather than 0\n",
    "df_mc.columns = ['cc']\n",
    "\n",
    "# drop duplicates. This could be dangerous if you have variables perfectly correlated with variables other than themse\n",
    "# for the sake of exercise, kept it in.\n",
    "df_mc.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mc[(df_mc.cc > .55) & (df_mc.cc < 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes on multicollinearity\n",
    "\n",
    "RENOVATED: Not sure what's better, to keep the binary or the year (but the year is wrong because it has zeros?) Maybe make a YEARS SINCE RENOVATED column.\n",
    "\n",
    "ABOVE v. LIVING: We see below that LIVING is strongly collinear with PRICE, which means we definitely want to keep LIVING. Probably this means we can delete ABOVE.\n",
    "\n",
    "GARAGE: Keep the binary or the area?\n",
    "\n",
    "BATHROOMS: Strongly collinear with LIVING, so we can probably delete BATHROOMS.\n",
    "\n",
    "HEAT SOURCES: These are the two most popular ones. I guess if it's not one, it's the other? Not sure whether to delete either here.\n",
    "\n",
    "BATHROOMS v. ABOVE: As discussed, probably drop both.\n",
    "\n",
    "BEDROOMS v. LIVING: Number isn't as high here, so maybe keep BEDROOMS.\n",
    "\n",
    "BATHROOMS v. BEDROOMS: Already going to kill BATHROOMS, so maybe keep BEDROOMS.\n",
    "\n",
    "ABOVE v. GARAGE: (?) Number isn't high, but if we get rid of GARAGE AREA and keep the binary this would go away.\n",
    "\n",
    "**FINAL WORD**:\n",
    "- do *something* about RENOVATED\n",
    "- keep the GARAGE binary\n",
    "- drop ABOVE and BATHROOMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "X = df_cont_std.drop(columns=['price'], axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15,8), sharey=True)\n",
    "\n",
    "for i, column in enumerate(X.columns):\n",
    "    # Locate applicable axes\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    ax = axes[row][col]\n",
    "\n",
    "    # Plot feature vs. y and label axes\n",
    "    ax.scatter(X[column], y, alpha=0.2)\n",
    "    ax.set_xlabel(column)\n",
    "    if col == 0:\n",
    "        ax.set_ylabel(\"SalePrice\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_garage', 'sqft_patio']\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=len(candidates), figsize=(8,20))\n",
    "\n",
    "for i, column in enumerate(candidates):\n",
    "    # Plot raw version\n",
    "    left_ax = axes[i][0]\n",
    "    left_ax.scatter(df[column], y, alpha=0.5)\n",
    "    left_ax.set_xlabel(column)\n",
    "    left_ax.set_ylabel('price')\n",
    "    \n",
    "    # Plot log transformed version\n",
    "    right_ax = axes[i][1]\n",
    "    right_ax.scatter(np.log(df[column]), np.log(y), alpha=0.5)\n",
    "    right_ax.set_xlabel(f\"log({column})\")\n",
    "    right_ax.set_ylabel(\"log(price)\")\n",
    "    \n",
    "fig.suptitle(\"Raw vs. Log Transformed\")\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stubbletrouble/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/series.py:726: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_log_cont = df.copy()\n",
    "\n",
    "for col in num_cont:\n",
    "    if col != 'price':\n",
    "        df_log[col] = np.log(df_log[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log_target = df.copy()\n",
    "\n",
    "df_log_target['price'] = np.log(df_log_target['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              -0.034184\n",
       "price            1.000000\n",
       "bedrooms         0.289204\n",
       "bathrooms        0.480401\n",
       "sqft_living      0.608521\n",
       "sqft_lot         0.085730\n",
       "floors           0.180576\n",
       "sqft_above       0.538651\n",
       "sqft_basement    0.245058\n",
       "sqft_garage      0.264169\n",
       "sqft_patio       0.313409\n",
       "yr_built         0.096013\n",
       "yr_renovated     0.084786\n",
       "lat              0.063632\n",
       "long            -0.022509\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              -0.034184\n",
       "price            1.000000\n",
       "bedrooms         0.289204\n",
       "bathrooms        0.480401\n",
       "sqft_living      0.514532\n",
       "sqft_lot         0.193742\n",
       "floors           0.180576\n",
       "sqft_above       0.466467\n",
       "sqft_basement    0.271570\n",
       "sqft_garage      0.312543\n",
       "sqft_patio       0.237249\n",
       "yr_built         0.096013\n",
       "yr_renovated     0.084786\n",
       "lat              0.063632\n",
       "long            -0.022509\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log.corr()['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              -0.024276\n",
       "price            1.000000\n",
       "bedrooms         0.346268\n",
       "bathrooms        0.516799\n",
       "sqft_living      0.621576\n",
       "sqft_lot         0.083969\n",
       "floors           0.234028\n",
       "sqft_above       0.547800\n",
       "sqft_basement    0.250714\n",
       "sqft_garage      0.285286\n",
       "sqft_patio       0.309753\n",
       "yr_built         0.120731\n",
       "yr_renovated     0.076076\n",
       "lat              0.074283\n",
       "long            -0.018707\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_log_target.corr()['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes on logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking log(PRICE) improves correlation for just about everything. Separately, LOT, BASEMENT, and GARAGE seem to improve correlation when they are logged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
